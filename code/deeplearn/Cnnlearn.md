## <center> CNN学习 </center>
#### 1、基本概念
- CNN(Convolutional neural network)卷积神经网络，是一种专门用来处理具有类似网格结构的数据的神经网络。常在图像处理领域使用。
- “卷积神经网络“使用了卷积这种数学运算。卷积是一种特殊的线性运算。
### CNN构成
CNN的结构如下图：
![](https://github.com/tianhao303/offer/raw/master/code/code_3/CNN.png)
#### 1、输入层
- 输入一般为2维的数组,或者RGB图像
#### 2、卷积层
- 卷积的概念：
    - 代表对前函数$x(a)$的操作，$w(t-a)$的延时根据情况而定，表示$x(a)$的前几个时刻的输入对当前的时刻的影响，一般输出的$s(t)$与$x(a)$和$w(t-a)$相比具有更好的平滑效果，用于平滑滤波。
    - 连续时 $s(t) = \int x(a)w(t-a)da$
    - 离散时 $s(t) = \sum x(a)w(t-a)$
    - 一般表示为$s(t) = x* w$
    - 在图像中，一个i*j的卷积，将图片卷积过程如下动图。
![](https://github.com/tianhao303/offer/raw/master/code/code_3/%E5%8D%B7%E7%A7%AF.gif)
  <center>卷积动态图</center>
![](https://github.com/tianhao303/offer/raw/master/code/code_3/%E5%A4%9A%E5%B1%82%E5%8D%B7%E7%A7%AF.webp)
-卷积的特点
  - 稀疏交互
    - 采用卷积通过局部信息去选择我们更感兴趣的点，相比以往神经网络的全连接，采用卷积有更小的模型参数，可以摒弃一些无用的信息，比如在图像中检测边缘时，与边缘离的较远的部分与边缘无关，采用卷积运算，可以只关注这一部分。
    - 参数共享
      - 每一个卷积核代表一组参数，一个卷积核的参数被整张图片共享
    - 等变表示
  
#### 3、池化
  -池化函数使用某一位置相邻输出总体的统计特征来代替网络在该位置的输出。
    - 池化函数类型
      - 最大池化(amx pooling)   给出其中的最大值
      - 平均值
      - $L^2$池化函数
      - 据中心像素的加权平均
- 不管采用什么样的池化函数，当输入做少量平移时，出花能够帮助输入的表示近似不变性，表示输入经过少量平移之后，其输出基本不变。
  - 1、不对边缘进行填充的下采样（有效卷积）
    - 假设池化卷积核大小为k,图像的宽度为m ,则经过池化后其图像输出的大小为m-k+1
    - 如果卷积核非常大，效率会非常高，使的输出大小迅速缩减，当网络层数过大时，其会缩减到1*1
  - 2、局部填充（相同卷积）
  - 3、全卷积
    - 进行全部补充，使每个像素点都可以被访问k次，最终输出的大小为m-K+1
  
#### 4、RELU层
    - 是神经元的激活函数，对输入值x的作用是max(0,x)，当然RELU只是一种选择，还有选Leak-Relu等等，一般都是用Relu！
#### 5、全连通层
    - 这个层就是一个常规的神经网络，它的作用是对经过多次卷积层和多次池化层所得出来的高级特征进行全连接
#### 5、输出层
    - 结构化输出

  